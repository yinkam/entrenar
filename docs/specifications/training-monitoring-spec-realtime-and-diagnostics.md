# Training Monitoring Specification: Real-Time Diagnostics

> **Version:** 0.1.0
> **Status:** Draft
> **Author:** PAIML Team
> **Toyota Way Principle:** è‡ªåƒåŒ– (Jidoka) - Build quality in through automation with human oversight

## Table of Contents

1. [Executive Summary](#1-executive-summary)
2. [Problem Statement](#2-problem-statement)
3. [Architecture Overview](#3-architecture-overview)
4. [Component Design](#4-component-design)
   - 4.1 Metrics Collection (trueno)
   - 4.2 Time-Series Storage (trueno-db)
   - 4.3 Visualization (trueno-viz)
   - 4.4 Dependency Graphs (trueno-graph)
   - 4.5 ML Diagnostics (aprender)
   - 4.6 Serving Hooks (realizar)
5. [Toyota Way Integration](#5-toyota-way-integration)
6. [API Specification](#6-api-specification)
7. [Data Schema](#7-data-schema)
8. [Alerting & Andon](#8-alerting--andon)
9. [Academic Foundation](#9-academic-foundation)
10. [Implementation Roadmap](#10-implementation-roadmap)
11. [Acceptance Criteria](#11-acceptance-criteria)

---

## 1. Executive Summary

Entrenar lacks visibility into training health. This spec defines a real-time monitoring system using existing PAIML infrastructure:

| Component | Tool | Purpose |
|-----------|------|---------|
| Compute | trueno | SIMD-accelerated metric aggregation |
| Storage | trueno-db | Time-series metrics persistence |
| Visualization | trueno-viz | Terminal/PNG dashboards |
| Dependencies | trueno-graph | Model lineage tracking |
| Diagnostics | aprender | Drift detection, anomaly detection |
| Assertions | renacer | Performance budgets & Andon checks |
| Serving | realizar | Production metric hooks |

**Key Deliverable:** `entrenar::monitor` module with Toyota Way quality built-in.

---

## 3. Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         ENTRENAR MONITOR                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  Training â”‚â”€â”€â”€â–ºâ”‚  Metrics  â”‚â”€â”€â”€â–ºâ”‚  trueno-  â”‚â”€â”€â”€â–ºâ”‚  trueno-  â”‚     â”‚
â”‚  â”‚   Loop    â”‚    â”‚ Collector â”‚    â”‚    db     â”‚    â”‚    viz    â”‚     â”‚
â”‚  â”‚ (entrenar)â”‚    â”‚ (trueno)  â”‚    â”‚ (storage) â”‚    â”‚ (display) â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚        â”‚                â”‚                  â”‚               â”‚           â”‚
â”‚        â”‚          â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”           â”‚           â”‚
â”‚        â”‚          â”‚  renacer  â”‚    â”‚  aprender â”‚           â”‚           â”‚
â”‚        â”‚          â”‚ (policies)â”‚    â”‚  (drift)  â”‚           â”‚           â”‚
â”‚        â”‚          â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”˜           â”‚           â”‚
â”‚        â”‚                â”‚                  â”‚               â”‚           â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                         â”‚                                             â”‚
â”‚                   â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚                   â”‚  Alerting â”‚â”€â”€â”€â–ºâ”‚  realizar â”‚                     â”‚
â”‚                   â”‚  (Andon)  â”‚    â”‚ (serving) â”‚                     â”‚
â”‚                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚                                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                    trueno-graph (lineage)                      â”‚   â”‚
â”‚  â”‚  model_v1 â”€â”€â–º model_v2 â”€â”€â–º model_v3 (accuracy: 85%â†’87%â†’82%)   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


### Data Flow (æ”¹å–„ Kaizen - Continuous Flow)

1. **Training emits metrics** â†’ `MetricsCollector` (every batch/epoch)
2. **Collector aggregates** â†’ SIMD via trueno (low overhead)
3. **Storage persists** â†’ trueno-db time-series (Parquet backend)
4. **Visualization renders** â†’ trueno-viz (terminal ASCII or PNG)
5. **Drift detection** â†’ aprender anomaly detection
6. **Alerts trigger** â†’ Andon system (stop-the-line on regression)
7. **Serving reports** â†’ realizar hooks for production metrics

---

## 2. Problem Statement

### Current State

```
Training runs â†’ stderr warnings â†’ lost â†’ no history
```

**Evidence from depyler-oracle (#154):**
- All 4 MoE experts failed silently
- Matrix singularity warnings ignored
- No accuracy metrics recorded
- Discovered only through manual investigation

### Gaps Identified

| Gap | Impact | Citation |
|-----|--------|----------|
| No metrics storage | Cannot track accuracy over time | [1] Sculley et al. 2015 |
| No drift detection | Silent model degradation | [2] Lu et al. 2018 |
| No training dashboard | Blind to convergence issues | [3] Amershi et al. 2019 |
| No A/B comparison | Cannot validate improvements | [4] Kohavi et al. 2020 |
| No alerting | Failures go unnoticed | [5] Breck et al. 2017 |

---

## 4. Component Design

### 4.1 Metrics Collection (trueno)

**Purpose:** Low-overhead metric aggregation using SIMD primitives.

```rust
use trueno::{Vector, Matrix};
use entrenar::monitor::{MetricsCollector, Metric};

// Zero-copy metric collection during training
let mut collector = MetricsCollector::new();

for epoch in 0..100 {
    let loss = train_epoch(&model, &data);
    let accuracy = evaluate(&model, &test_data);

    // SIMD-accelerated running statistics
    collector.record(Metric::Loss, loss);
    collector.record(Metric::Accuracy, accuracy);
    collector.record(Metric::LearningRate, optimizer.lr());
    collector.record(Metric::GradientNorm, gradients.norm());
}

// Aggregates computed via trueno::Vector operations
let stats = collector.summary();  // mean, std, min, max, percentiles
```

**Overhead Target:** <1% of training time (per [6] Lipton & Steinhardt 2018).

### 4.2 Time-Series Storage (trueno-db)

**Purpose:** Persist metrics for historical analysis and drift detection.

```rust
use trueno_db::{Database, TimeSeriesTable};

let db = Database::open("training_metrics.parquet")?;

// Schema: timestamp, model_id, metric_name, value
let metrics_table = db.create_table("metrics", &[
    ("timestamp", DataType::Timestamp),
    ("model_id", DataType::String),
    ("metric", DataType::String),
    ("value", DataType::Float64),
])?;

// Batch insert (GPU-accelerated if available)
metrics_table.insert_batch(&collector.to_records())?;

// SQL queries for analysis
let recent = db.query("
    SELECT metric, AVG(value), STDDEV(value)
    FROM metrics
    WHERE timestamp > NOW() - INTERVAL '1 hour'
    GROUP BY metric
")?;
```

### 4.3 Visualization (trueno-viz)

**Purpose:** Real-time training dashboards in terminal or PNG.

```rust
use trueno_viz::prelude::*;
use trueno_viz::output::{TerminalEncoder, TerminalMode};

// Loss curve over epochs
let loss_plot = LinePlot::new()
    .x(&epochs)
    .y(&losses)
    .title("Training Loss")
    .build()?;

// Accuracy comparison (train vs val)
let acc_plot = LinePlot::new()
    .series("train", &train_acc)
    .series("val", &val_acc)
    .title("Accuracy")
    .build()?;

// Render to terminal (ASCII mode for SSH)
let dashboard = Dashboard::new()
    .add(loss_plot, 0, 0)
    .add(acc_plot, 0, 1)
    .build()?;

TerminalEncoder::new()
    .mode(TerminalMode::Ascii)
    .refresh_rate(Duration::from_secs(1))
    .print(&dashboard);
```

### 4.4 Dependency Graphs (trueno-graph)

**Purpose:** Track model lineage and training dependencies.

```rust
use trueno_graph::{CsrGraph, NodeId};

let mut lineage = CsrGraph::new();

// Track model versions
let v1 = lineage.add_node("model_v1", ModelMetadata { accuracy: 0.85 })?;
let v2 = lineage.add_node("model_v2", ModelMetadata { accuracy: 0.87 })?;
let v3 = lineage.add_node("model_v3", ModelMetadata { accuracy: 0.82 })?;

// Track derivation (v1 â†’ v2 via more data, v2 â†’ v3 via hyperparameter change)
lineage.add_edge(v1, v2, "add_training_data")?;
lineage.add_edge(v2, v3, "tune_hyperparams")?;

// Query: Which training run caused regression?
let regression_source = lineage.find_regression_source(v3)?;
// Returns: v2 â†’ v3 edge (hyperparameter change)
```

### 4.5 ML Diagnostics (aprender)

**Purpose:** Automated drift detection and anomaly alerting.

```rust
use aprender::metrics::drift::{DriftDetector, DriftConfig, DriftStatus};
use aprender::anomaly::IsolationForest;

// Drift detection (per [2] Lu et al. 2018)
let detector = DriftDetector::new(
    DriftConfig::default()
        .with_window_size(100)
        .with_threshold(0.05)  // 5% significance
);

let status = detector.detect_performance_drift(&baseline_acc, &current_acc);
match status {
    DriftStatus::NoDrift => {},
    DriftStatus::Warning(p) => println!("âš ï¸ Potential drift (p={})", p),
    DriftStatus::Drift(p) => trigger_andon("ğŸ›‘ DRIFT DETECTED", p),
}

// Anomaly detection for training metrics
let forest = IsolationForest::new(100, 256);
forest.fit(&historical_metrics)?;
let anomaly_scores = forest.score_samples(&current_metrics);
```

### 4.6 Syscall-Level Tracing (renacer)

**Purpose:** Deep system-level anomaly detection using renacer patterns.

```rust
use renacer::{SlidingWindowBaseline, AnomalySeverity};

// Reuse renacer's anomaly detection for training metrics
let baseline = SlidingWindowBaseline::new(100);  // 100-sample window

for metric_value in training_metrics {
    baseline.update(metric_value);

    if let Some(anomaly) = baseline.detect_anomaly(metric_value, 3.0) {
        match anomaly.severity {
            AnomalySeverity::Low => log_warning(&anomaly),
            AnomalySeverity::Medium => trigger_alert(&anomaly),
            AnomalySeverity::High => trigger_andon(&anomaly),
        }
    }
}
```

**Patterns borrowed from renacer:**
- Sliding window baselines (per-metric independent windows)
- Z-score anomaly detection with configurable thresholds
- Severity classification (Low: 3-4Ïƒ, Medium: 4-5Ïƒ, High: >5Ïƒ)
- SIMD-accelerated percentile computation (P50, P90, P99)

### 4.6 Serving Hooks (realizar)

**Purpose:** Connect training metrics to production monitoring.

```rust
use realizar::metrics::{MetricsExporter, PrometheusFormat};

// Export training metrics in Prometheus format
let exporter = MetricsExporter::new()
    .format(PrometheusFormat)
    .endpoint("/metrics");

// Register training metrics
exporter.register_gauge("model_accuracy", "Current model accuracy");
exporter.register_histogram("inference_latency", "Inference latency distribution");

// Push metrics to realizar serving endpoint
exporter.push(&collector.summary())?;

// Production A/B comparison
let ab_result = realizar::ab_test(
    model_a: "model_v2",
    model_b: "model_v3",
    traffic_split: 0.1,  // 10% to new model
    metric: "accuracy",
)?;
```

### 4.7 Performance Assertions (renacer)

**Purpose:** Enforce performance budgets and "Stop the Line" (Andon) logic.

```rust
use renacer::assertions::{AssertionRunner, AssertionConfig};

// Load budgets from renacer.toml
let config = AssertionConfig::from_file("renacer.toml")?;
let mut runner = AssertionRunner::new(config);

// In training loop:
runner.check_latency("training_iteration", duration)?;
runner.check_memory("model_params", memory_usage)?;

// If budget exceeded:
// 1. renacer logs violation
// 2. Returns Result::Err if fail_on_violation = true
// 3. Triggers Andon signal
```

---

## 5. Toyota Way Integration

### è‡ªåƒåŒ– (Jidoka) - Automation with Human Touch

**Principle:** Automatically detect abnormalities, stop the line, alert humans.

| Trigger | Action | Human Escalation |
|---------|--------|------------------|
| Accuracy < threshold | Pause training | Alert: "Accuracy regression detected" |
| Loss divergence (NaN/Inf) | Stop immediately | Alert: "Training diverged" |
| Gradient explosion | Reduce LR automatically | Alert: "Gradient clipping triggered" |
| Renacer Budget Violated | **Andon Stop** | Alert: "Performance regression (Latency/Mem)" |

### ç¾åœ°ç¾ç‰© (Genchi Genbutsu) - Go and See

**Principle:** Real data, not assumptions. Metrics must reflect actual training.

```rust
// Every metric must be measured, not inferred
assert!(collector.is_measured(Metric::Accuracy));  // Not estimated
assert!(collector.sample_count() >= MIN_SAMPLES);  // Statistically valid
```

### æ”¹å–„ (Kaizen) - Continuous Improvement

**Principle:** Track improvement over time, identify regressions.

```rust
// Model lineage tracks improvement
let improvement = lineage.compare(v1, v3);
// Returns: accuracy +2%, latency -15%, size -10%
```

### åçœ (Hansei) - Reflection

**Principle:** Post-training analysis to identify root causes of failures.

```rust
// Automatic post-mortem generation
let report = monitor.generate_postmortem(training_run_id);
// Includes: convergence analysis, anomaly timeline, recommendations
```

---

## 6. API Specification

### Core Traits

```rust
/// Emits metrics during training
pub trait MetricsEmitter {
    fn emit(&mut self, metric: Metric, value: f64);
    fn emit_batch(&mut self, metrics: &[(Metric, f64)]);
    fn flush(&mut self) -> Result<()>;
}

/// Stores metrics persistently
pub trait MetricsStore {
    fn write(&mut self, record: MetricRecord) -> Result<()>;
    fn query(&self, query: &str) -> Result<Vec<MetricRecord>>;
    fn range(&self, start: Timestamp, end: Timestamp) -> Result<Vec<MetricRecord>>;
}

/// Detects training anomalies
pub trait AnomalyDetector {
    fn fit(&mut self, historical: &[f64]) -> Result<()>;
    fn is_anomaly(&self, value: f64) -> bool;
    fn anomaly_score(&self, value: f64) -> f64;
}

/// Visualizes training progress
pub trait Dashboard {
    fn update(&mut self, metrics: &MetricsSummary);
    fn render(&self) -> Result<Framebuffer>;
    fn save_png(&self, path: &Path) -> Result<()>;
}
```

### Entry Points

```rust
// Simple: Auto-configured monitoring
let monitor = Monitor::auto()?;

// Custom: Full control
let monitor = Monitor::builder()
    .storage(TruenoDB::open("metrics.parquet")?)
    .visualizer(TruenoViz::terminal())
    .drift_detector(DriftDetector::default())
    .assertions(Renacer::from_config("renacer.toml")?)
    .alerting(AndonConfig::default())
    .build()?;
```

---

## 7. Data Schema

### MetricRecord (Parquet)

| Field | Type | Description |
|-------|------|-------------|
| `timestamp` | TIMESTAMP | Metric collection time |
| `run_id` | STRING | Training run identifier |
| `epoch` | INT32 | Training epoch |
| `batch` | INT32 | Batch within epoch |
| `metric` | STRING | Metric name (loss, accuracy, etc.) |
| `value` | FLOAT64 | Metric value |
| `tags` | MAP<STRING,STRING> | Custom labels |

### ModelLineage (trueno-graph)

| Node Field | Type | Description |
|------------|------|-------------|
| `model_id` | STRING | Unique model identifier |
| `version` | STRING | Semantic version |
| `accuracy` | FLOAT64 | Validation accuracy |
| `created_at` | TIMESTAMP | Training completion time |
| `config_hash` | STRING | Hyperparameter hash |

| Edge Field | Type | Description |
|------------|------|-------------|
| `parent_id` | STRING | Source model |
| `child_id` | STRING | Derived model |
| `change_type` | STRING | What changed (data, hyperparams, arch) |

---

## 8. Alerting & Andon

### Alert Levels

| Level | Trigger | Action |
|-------|---------|--------|
| **INFO** | Training started/completed | Log only |
| **WARNING** | Accuracy dip >5% | Log + optional notification |
| **ERROR** | Training diverged | Stop training + notify |
| **CRITICAL** | Renacer Budget Violation | **Andon Stop** + page on-call |

### Andon Implementation (via Renacer)

```rust
use renacer::Andon;

pub struct AndonSystem {
    renacer: Andon,
    handlers: Vec<Box<dyn AlertHandler>>,
}

impl AndonSystem {
    pub fn trigger(&self, alert: Alert) {
        // Renacer determines if this is a stop-the-line event
        if self.renacer.should_stop(&alert) {
            self.stop_training();
            self.notify_all(&alert);
            self.create_incident(&alert);
        } else {
            self.log(&alert);
        }
    }
}
```

---

## 9. Academic Foundation

### Peer-Reviewed Citations

| # | Citation | Relevance |
|---|----------|-----------|
| [1] | Sculley, D., et al. (2015). **Hidden Technical Debt in Machine Learning Systems.** NeurIPS. | ML systems accumulate debt; monitoring is essential for maintenance |
| [2] | Lu, J., et al. (2018). **Learning under Concept Drift: A Review.** IEEE TKDE. | Drift detection algorithms (DDM, ADWIN, Page-Hinkley) |
| [3] | Amershi, S., et al. (2019). **Software Engineering for Machine Learning.** ICSE-SEIP. | Microsoft's 9 stages of ML; monitoring spans stages 6-9 |
| [4] | Kohavi, R., et al. (2020). **Trustworthy Online Controlled Experiments.** Cambridge Press. | A/B testing best practices for ML models |
| [5] | Breck, E., et al. (2017). **The ML Test Score.** IEEE BigData. | Google's ML testing rubric; monitoring is 25% of score |
| [6] | Lipton, Z., Steinhardt, J. (2018). **Troubling Trends in Machine Learning Scholarship.** ICML. | Importance of rigorous measurement over claims |
| [7] | Paleyes, A., et al. (2022). **Challenges in Deploying ML: A Survey.** ACM Computing Surveys. | Production ML failure modes; monitoring gaps |
| [8] | Polyzotis, N., et al. (2018). **Data Lifecycle Challenges in Production ML.** SIGMOD. | Google's TFX pipeline; data validation patterns |
| [9] | Schelter, S., et al. (2018). **Automating Large-Scale Data Quality Verification.** VLDB. | Amazon's Deequ; statistical data validation |
| [10] | Klaise, J., et al. (2021). **Monitoring ML Models in Production.** arXiv:2111.13657. | Alibi Detect; drift detection taxonomy |

### Key Insights Applied

**From [1] Sculley (Technical Debt):**
> "Only a small fraction of real-world ML systems is composed of the ML code... monitoring is critical infrastructure."

Applied: Monitor module is first-class, not afterthought.

**From [5] Breck (ML Test Score):**
> "Tests for model staleness... tests for NaN, Inf... tests for training-serving skew."

Applied: Andon triggers for NaN/Inf, drift detection for staleness.

**From [8] Polyzotis (TFX):**
> "Data validation should be automated and continuous."

Applied: trueno-db stores all metrics; queries enable automated validation.

---

## 10. Implementation Roadmap

### Phase 1: Core Metrics (ENT-041)
- [ ] `MetricsCollector` with trueno SIMD aggregation
- [ ] Basic metrics: loss, accuracy, learning_rate, gradient_norm
- [ ] JSON export for immediate visibility
- **Estimate:** 8 hours

### Phase 2: Storage (ENT-042)
- [ ] trueno-db integration for Parquet persistence
- [ ] SQL query interface for historical analysis
- [ ] Retention policies (7 days default)
- **Estimate:** 12 hours

### Phase 3: Visualization (ENT-043)
- [ ] trueno-viz terminal dashboard
- [ ] Loss/accuracy curves
- [ ] Real-time refresh (1s interval)
- **Estimate:** 8 hours

### Phase 4: Drift Detection (ENT-044)
- [ ] aprender DriftDetector integration
- [ ] Page-Hinkley test for accuracy drift
- [ ] IsolationForest for metric anomalies
- **Estimate:** 12 hours

### Phase 5: Alerting (ENT-045)
- [ ] Andon system with alert levels
- [ ] Stop-the-line on critical failures
- [ ] Webhook notifications (optional)
- **Estimate:** 8 hours

### Phase 6: Lineage (ENT-046)
- [ ] trueno-graph model lineage tracking
- [ ] Regression source identification
- [ ] Parquet persistence for lineage
- **Estimate:** 8 hours

### Phase 7: Serving Hooks (ENT-047)
- [ ] realizar metrics exporter
- [ ] Prometheus format support
- [ ] A/B test integration
- **Estimate:** 8 hours

### Phase 8: WASM Dashboard (ENT-048) - Future
- [ ] wasm-bindgen exports for browser
- [ ] Canvas rendering (reuse trueno-viz patterns)
- [ ] SIMD128 for browser-side stats
- [ ] e2e tests with headless browser
- **Estimate:** 16 hours

**Total:** 80 hours (10 days @ 8h/day)

**Priority:** ASCII terminal first (Phases 1-7), WASM browser later (Phase 8)

---

## 11. Acceptance Criteria

### Functional Requirements

- [x] Training runs emit metrics automatically
- [ ] Metrics persist to trueno-db (queryable via SQL) *(InMemoryStore/JsonFileStore done; trueno-db pending)*
- [x] Terminal dashboard shows live loss/accuracy curves
- [x] Drift detection triggers WARNING at 5% accuracy drop
- [x] Andon stops training on NaN/Inf loss
- [x] Model lineage tracks parent-child relationships
- [x] Metrics exportable to Prometheus format

### Performance Requirements

- [x] Monitoring overhead < 1% of training time *(20K records in <100ms)*
- [x] Dashboard refresh latency < 100ms *(verified)*
- [x] Storage write latency < 10ms per batch *(O(1) running stats)*
- [ ] Query latency < 100ms for 1M records *(trueno-db integration pending)*

### Quality Requirements

- [x] Test coverage > 90% *(92.53% achieved)*
- [ ] Mutation score > 80% *(pending verification)*
- [x] Documentation for all public APIs
- [ ] Integration tests with depyler-oracle

### Toyota Way Compliance

- [x] Jidoka: Automatic anomaly detection implemented
- [x] Genchi Genbutsu: All metrics are measured, not inferred
- [x] Kaizen: Historical comparison enables improvement tracking
- [x] Hansei: Post-training reports identify failure root causes *(HanseiAnalyzer)*

---

## Appendix: File Structure

```
src/monitor/
â”œâ”€â”€ mod.rs              # Public API + MetricsCollector (Welford's algorithm)
â”œâ”€â”€ storage.rs          # InMemoryStore, JsonFileStore
â”œâ”€â”€ dashboard.rs        # ASCII terminal dashboard with sparklines
â”œâ”€â”€ drift.rs            # Sliding window anomaly detection (z-score)
â”œâ”€â”€ andon.rs            # Toyota Way alerting system (Jidoka)
â”œâ”€â”€ lineage.rs          # Model version tracking and regression analysis
â”œâ”€â”€ export.rs           # Prometheus/JSON/CSV export formats
â”œâ”€â”€ report.rs           # Hansei post-training reports and recommendations
â””â”€â”€ tests.rs            # 88 module tests (incl. 5 perf benchmarks)
```

---

*Document generated: 2024-11-27*
*Status: DRAFT - Pending code review*

