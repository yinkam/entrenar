<!DOCTYPE HTML>
<html lang="en" class="rust sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Core Concepts - Entrenar - Training &amp; Optimization Library</title>


        <!-- Custom HTML head -->

        <meta name="description" content="A comprehensive guide to building neural network training systems with autograd, optimizers, LoRA/QLoRA, and quantization using EXTREME TDD methodology">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="../favicon.svg">
        <link rel="shortcut icon" href="../favicon.png">
        <link rel="stylesheet" href="../css/variables.css">
        <link rel="stylesheet" href="../css/general.css">
        <link rel="stylesheet" href="../css/chrome.css">
        <link rel="stylesheet" href="../css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="../FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="../fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="../highlight.css">
        <link rel="stylesheet" href="../tomorrow-night.css">
        <link rel="stylesheet" href="../ayu-highlight.css">

        <!-- Custom theme stylesheets -->


        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "../";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "rust";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="../toc.js"></script>
    </head>
    <body>
    <div id="body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('rust')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var sidebar = null;
            var sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            sidebar_toggle.checked = sidebar === 'visible';
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="../toc.html"></iframe>
            </noscript>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Entrenar - Training &amp; Optimization Library</h1>

                    <div class="right-buttons">
                        <a href="../print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/paiml/entrenar" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>
                        <a href="https://github.com/paiml/entrenar/edit/main/book/src/getting-started/core-concepts.md" title="Suggest an edit" aria-label="Suggest an edit">
                            <i id="git-edit-button" class="fa fa-edit"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="core-concepts"><a class="header" href="#core-concepts">Core Concepts</a></h1>
<p>This chapter explains the fundamental concepts behind Entrenar's design and how they work together to provide a complete neural network training system.</p>
<h2 id="architecture-overview"><a class="header" href="#architecture-overview">Architecture Overview</a></h2>
<p>Entrenar is built on four core pillars:</p>
<pre><code>┌─────────────────────────────────────────────────────────┐
│                    Training Loop                        │
│  (User Code: forward pass, loss, backward, optimize)    │
└─────────────────────────────────────────────────────────┘
                           │
        ┌──────────────────┼──────────────────┐
        ▼                  ▼                  ▼
┌───────────────┐  ┌───────────────┐  ┌───────────────┐
│   Autograd    │  │  Optimizers   │  │   LoRA/QLoRA  │
│   Engine      │  │  (SGD, Adam,  │  │  (Parameter-  │
│   (Gradient   │  │   AdamW, LR   │  │   Efficient   │
│   Computation)│  │   Schedulers) │  │   Fine-Tuning)│
└───────────────┘  └───────────────┘  └───────────────┘
        │                  │                  │
        └──────────────────┼──────────────────┘
                           ▼
                   ┌───────────────┐
                   │     Tensor    │
                   │ (Data + Grad) │
                   └───────────────┘
</code></pre>
<h2 id="1-tensors"><a class="header" href="#1-tensors">1. Tensors</a></h2>
<p><strong>Tensors</strong> are the fundamental data structure in Entrenar, representing multi-dimensional arrays with optional gradient tracking.</p>
<h3 id="tensor-creation"><a class="header" href="#tensor-creation">Tensor Creation</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use entrenar::Tensor;

// Scalar (0D)
let scalar = Tensor::from_vec(vec![3.14], false);

// Vector (1D)
let vector = Tensor::from_vec(vec![1.0, 2.0, 3.0], true);

// Matrix (2D) - flattened representation
let matrix = Tensor::from_vec(
    vec![1.0, 2.0,
         3.0, 4.0],  // 2x2 matrix
    true
);

// Random initialization
let weights = Tensor::randn(vec![256], true);  // Normal(0, 1)

// Zero initialization
let bias = Tensor::zeros(vec![128], true);
<span class="boring">}</span></code></pre></pre>
<h3 id="gradient-tracking"><a class="header" href="#gradient-tracking">Gradient Tracking</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Trainable parameter
let w = Tensor::from_vec(vec![1.0, 2.0], true);  // requires_grad=true
assert!(w.requires_grad());

// Frozen parameter (e.g., pretrained base weights)
let frozen = Tensor::from_vec(vec![1.0, 2.0], false);  // requires_grad=false
assert!(!frozen.requires_grad());
<span class="boring">}</span></code></pre></pre>
<h3 id="tensor-operations"><a class="header" href="#tensor-operations">Tensor Operations</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Arithmetic operations
let a = Tensor::from_vec(vec![1.0, 2.0], true);
let b = Tensor::from_vec(vec![3.0, 4.0], true);

let c = &amp;a + &amp;b;  // Element-wise addition
let d = &amp;a * &amp;b;  // Element-wise multiplication
let e = &amp;a - &amp;b;  // Element-wise subtraction

// Matrix operations
use entrenar::autograd::ops::matmul;

let result = matmul(&amp;a, &amp;b, rows, cols, batch_size);
<span class="boring">}</span></code></pre></pre>
<p><strong>Key Insight</strong>: Tensor operations use references (<code>&amp;</code>) to avoid consuming the original tensors, allowing reuse in computational graphs.</p>
<h2 id="2-automatic-differentiation-autograd"><a class="header" href="#2-automatic-differentiation-autograd">2. Automatic Differentiation (Autograd)</a></h2>
<p><strong>Autograd</strong> computes gradients automatically using reverse-mode differentiation (backpropagation).</p>
<h3 id="computational-graph"><a class="header" href="#computational-graph">Computational Graph</a></h3>
<p>Entrenar uses a <strong>tape-based</strong> computational graph:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let x = Tensor::from_vec(vec![2.0], true);
let y = &amp;x * &amp;x;           // y = x²  (tape records: mul operation)
let z = &amp;y + &amp;x;           // z = x² + x  (tape records: add operation)

backward(&amp;z);              // Compute dz/dx

println!("dz/dx = {}", x.grad()[0]);  // dz/dx = 2x + 1 = 5.0
<span class="boring">}</span></code></pre></pre>
<p><strong>Tape Structure</strong>:</p>
<pre><code>Tape:
  1. Op: Mul(x, x) -&gt; y
  2. Op: Add(y, x) -&gt; z

Backward pass (reverse order):
  1. dz/dz = 1.0
  2. dz/dy = 1.0, dz/dx += 1.0
  3. dy/dx = 2x, dz/dx += 2x * dz/dy = 4.0
  Result: dz/dx = 5.0
</code></pre>
<h3 id="supported-operations"><a class="header" href="#supported-operations">Supported Operations</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Operation</th><th>Forward</th><th>Backward</th></tr></thead><tbody>
<tr><td><strong>Matrix Mul</strong></td><td><code>C = A @ B</code></td><td><code>dA = dC @ B^T</code>, <code>dB = A^T @ dC</code></td></tr>
<tr><td><strong>ReLU</strong></td><td><code>max(0, x)</code></td><td><code>dx = (x &gt; 0) ? dy : 0</code></td></tr>
<tr><td><strong>GELU</strong></td><td><code>x * Φ(x)</code></td><td>Chain rule with Gaussian CDF</td></tr>
<tr><td><strong>Layer Norm</strong></td><td><code>(x - μ) / σ</code></td><td>Mean/variance gradients</td></tr>
<tr><td><strong>Attention</strong></td><td><code>softmax(QK^T/√d)V</code></td><td>Q, K, V chain rule</td></tr>
</tbody></table>
</div>
<h3 id="gradient-checking"><a class="header" href="#gradient-checking">Gradient Checking</a></h3>
<p>Entrenar validates all gradients with finite differences:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[test]
fn test_gradient_correctness() {
    let x = Tensor::from_vec(vec![1.0, 2.0], true);
    let y = &amp;x * &amp;x;

    backward(&amp;y);

    // Finite difference: f(x+ε) - f(x-ε) / 2ε
    let epsilon = 1e-3;
    let threshold = 0.2;  // 20% relative error tolerance

    check_gradient(&amp;y, &amp;x, epsilon, threshold);  // ✅ Passes
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Zero-tolerance policy</strong>: Every operation has gradient checking tests ensuring mathematical correctness.</p>
<h2 id="3-optimizers"><a class="header" href="#3-optimizers">3. Optimizers</a></h2>
<p><strong>Optimizers</strong> update parameters using computed gradients.</p>
<h3 id="optimizer-interface"><a class="header" href="#optimizer-interface">Optimizer Interface</a></h3>
<p>All optimizers share a common interface:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use entrenar::optim::{SGD, Adam, AdamW};

let mut optimizer = Adam::default_params(learning_rate=0.001);

// Training step
backward(&amp;loss);
optimizer.step(&amp;mut [&amp;mut w1, &amp;mut b1, &amp;mut w2, &amp;mut b2]);

// Zero gradients for next iteration
w1.zero_grad();
b1.zero_grad();
// ... etc
<span class="boring">}</span></code></pre></pre>
<h3 id="sgd-stochastic-gradient-descent"><a class="header" href="#sgd-stochastic-gradient-descent">SGD (Stochastic Gradient Descent)</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use entrenar::optim::SGD;

let mut sgd = SGD::new(
    learning_rate=0.01,
    momentum=0.9,           // Accelerates convergence
);

// Update rule: v = momentum * v + grad
//              param = param - learning_rate * v
sgd.step(&amp;mut params);
<span class="boring">}</span></code></pre></pre>
<p><strong>Use case</strong>: Simple optimization, baseline comparisons</p>
<h3 id="adam-adaptive-moment-estimation"><a class="header" href="#adam-adaptive-moment-estimation">Adam (Adaptive Moment Estimation)</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use entrenar::optim::Adam;

let mut adam = Adam::default_params(learning_rate=0.001);

// Adaptive learning rates per parameter
// m = β1*m + (1-β1)*grad           (1st moment)
// v = β2*v + (1-β2)*grad²          (2nd moment)
// param = param - lr * m̂ / (√v̂ + ε)
adam.step(&amp;mut params);
<span class="boring">}</span></code></pre></pre>
<p><strong>Use case</strong>: General-purpose, works well out-of-the-box</p>
<h3 id="adamw-adam-with-decoupled-weight-decay"><a class="header" href="#adamw-adam-with-decoupled-weight-decay">AdamW (Adam with Decoupled Weight Decay)</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use entrenar::optim::AdamW;

let mut adamw = AdamW::new(
    learning_rate=0.001,
    weight_decay=0.01,      // L2 regularization
    beta1=0.9,
    beta2=0.999,
    epsilon=1e-8,
);

// Decoupled weight decay: param = param * (1 - wd)
adamw.step(&amp;mut params);
<span class="boring">}</span></code></pre></pre>
<p><strong>Use case</strong>: Fine-tuning transformers, improved generalization</p>
<h3 id="learning-rate-schedulers"><a class="header" href="#learning-rate-schedulers">Learning Rate Schedulers</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use entrenar::optim::schedulers::CosineScheduler;

let scheduler = CosineScheduler::new(
    initial_lr=0.1,
    min_lr=0.001,
    total_steps=1000,
);

for step in 0..1000 {
    let lr = scheduler.get_lr(step);  // Cosine annealing
    optimizer.set_lr(lr);

    // ... training step ...
}
<span class="boring">}</span></code></pre></pre>
<h2 id="4-lora-low-rank-adaptation"><a class="header" href="#4-lora-low-rank-adaptation">4. LoRA (Low-Rank Adaptation)</a></h2>
<p><strong>LoRA</strong> enables parameter-efficient fine-tuning by freezing base weights and training low-rank adapters.</p>
<h3 id="architecture"><a class="header" href="#architecture">Architecture</a></h3>
<pre><code>Original Layer: W ∈ ℝ^(d_out × d_in)

LoRA Layer:
  Base: W ∈ ℝ^(d_out × d_in)     [FROZEN, requires_grad=false]
  Adapters:
    A ∈ ℝ^(rank × d_in)          [TRAINABLE, requires_grad=true]
    B ∈ ℝ^(d_out × rank)         [TRAINABLE, requires_grad=true]

Output: y = Wx + (α/r)(B(Ax))
</code></pre>
<h3 id="usage"><a class="header" href="#usage">Usage</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use entrenar::lora::LoRALayer;

// Pretrained base weights (frozen)
let base_weight = Tensor::from_vec(vec![...], false);

// Create LoRA layer
let lora = LoRALayer::new(
    base_weight,
    d_out=256,
    d_in=256,
    rank=16,       // Low-rank bottleneck
    alpha=32.0,    // Scaling factor
);

// Forward pass
let output = lora.forward(&amp;input);

// Only LoRA adapters receive gradients
backward(&amp;loss);  // base_weight.grad() remains zero
<span class="boring">}</span></code></pre></pre>
<h3 id="parameter-efficiency"><a class="header" href="#parameter-efficiency">Parameter Efficiency</a></h3>
<pre><code>Full Fine-Tuning: 7B parameters trainable
LoRA (rank=64):   8M parameters trainable (0.1%)

Memory savings: 99.9% reduction in trainable parameters
</code></pre>
<h3 id="adapter-persistence"><a class="header" href="#adapter-persistence">Adapter Persistence</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use entrenar::lora::adapter::{save_adapter, load_adapter};

// Save LoRA adapters (32MB file)
save_adapter(&amp;lora, rank=16, alpha=32.0, "adapter.json")?;

// Load adapters (without full model weights)
let loaded_lora = load_adapter("adapter.json", base_weight)?;
<span class="boring">}</span></code></pre></pre>
<p><strong>Use case</strong>: Share fine-tuned adapters without distributing 28GB base model weights</p>
<h2 id="5-qlora-quantized-lora"><a class="header" href="#5-qlora-quantized-lora">5. QLoRA (Quantized LoRA)</a></h2>
<p><strong>QLoRA</strong> reduces memory by 75% through 4-bit quantization of frozen base weights.</p>
<h3 id="4-bit-quantization"><a class="header" href="#4-bit-quantization">4-Bit Quantization</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use entrenar::lora::QLoRALayer;

// Base weights quantized to 4-bit (75% memory reduction)
let qlora = QLoRALayer::new(
    base_weight,
    d_out=4096,
    d_in=4096,
    rank=64,
    alpha=128.0,
);

// On-the-fly dequantization during forward pass
let output = qlora.forward(&amp;input);
<span class="boring">}</span></code></pre></pre>
<h3 id="memory-comparison"><a class="header" href="#memory-comparison">Memory Comparison</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Configuration</th><th>LoRA Memory</th><th>QLoRA Memory</th><th>Savings</th></tr></thead><tbody>
<tr><td><strong>Small (256-dim, 6 layers)</strong></td><td>1.5 MB</td><td>0.5 MB</td><td>65%</td></tr>
<tr><td><strong>Medium (768-dim, 12 layers)</strong></td><td>27 MB</td><td>8 MB</td><td>68%</td></tr>
<tr><td><strong>Large (4096-dim, 32 layers)</strong></td><td>4.2 GB</td><td>1.2 GB</td><td>70%</td></tr>
</tbody></table>
</div>
<h3 id="quantization-details"><a class="header" href="#quantization-details">Quantization Details</a></h3>
<pre><code>Block-wise quantization (64 elements per block):
  1. Compute scale factor: s = max(|values|) / 7
  2. Quantize: q = round(value / s)  ∈ [-7, 7]
  3. Store: 4-bit signed integers (15 discrete levels)

Dequantization:
  value = q * s  (full precision restored)
</code></pre>
<p><strong>Trade-off</strong>: Minimal accuracy loss (&lt;1%) for 75% memory reduction</p>
<h2 id="6-extreme-tdd-quality"><a class="header" href="#6-extreme-tdd-quality">6. EXTREME TDD Quality</a></h2>
<p>Entrenar is built with <strong>zero-tolerance for defects</strong> using multiple testing strategies:</p>
<h3 id="unit-tests"><a class="header" href="#unit-tests">Unit Tests</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[test]
fn test_matmul_correctness() {
    let a = Tensor::from_vec(vec![1.0, 2.0, 3.0, 4.0], false);
    let b = Tensor::from_vec(vec![5.0, 6.0, 7.0, 8.0], false);

    let c = matmul(&amp;a, &amp;b, 2, 2, 1);

    assert_eq!(c.data()[0], 19.0);  // 1*5 + 2*7
    assert_eq!(c.data()[1], 43.0);  // 3*5 + 4*7
}
<span class="boring">}</span></code></pre></pre>
<h3 id="property-based-tests"><a class="header" href="#property-based-tests">Property-Based Tests</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use proptest::prelude::*;

proptest! {
    #[test]
    fn test_adam_converges(lr in 0.05f32..0.5) {
        let optimizer = Adam::default_params(lr);
        assert!(converges_to_minimum(optimizer, 100));
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="gradient-checking-1"><a class="header" href="#gradient-checking-1">Gradient Checking</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[test]
fn test_relu_gradient() {
    let x = Tensor::from_vec(vec![-1.0, 0.0, 1.0], true);
    let y = relu(&amp;x);

    backward(&amp;y);

    // Finite difference validation (ε=1e-3, threshold=0.2)
    check_gradient(&amp;y, &amp;x, 1e-3, 0.2);
}
<span class="boring">}</span></code></pre></pre>
<h3 id="mutation-testing"><a class="header" href="#mutation-testing">Mutation Testing</a></h3>
<pre><code class="language-bash">cargo mutants --file src/autograd/ops.rs

# Ensures tests catch intentional bugs
# Target: &gt;80% mutation kill rate
</code></pre>
<h2 id="putting-it-all-together"><a class="header" href="#putting-it-all-together">Putting It All Together</a></h2>
<h3 id="complete-training-workflow"><a class="header" href="#complete-training-workflow">Complete Training Workflow</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use entrenar::{Tensor, backward, optim::AdamW, lora::QLoRALayer};

// 1. Load pretrained base weights
let base_weight = load_pretrained_weights("llama-7b.bin");

// 2. Create QLoRA layer (75% memory reduction)
let qlora = QLoRALayer::new(base_weight, 4096, 4096, rank=64, alpha=128.0);

// 3. Initialize optimizer
let mut optimizer = AdamW::new(lr=0.0001, weight_decay=0.01, ...);

// 4. Training loop
for (input, target) in dataloader {
    // Forward pass
    let output = qlora.forward(&amp;input);
    let loss = cross_entropy_loss(&amp;output, &amp;target);

    // Backward pass (only LoRA adapters get gradients)
    backward(&amp;loss);

    // Update (only 8M parameters instead of 7B)
    optimizer.step(&amp;mut qlora.trainable_parameters());

    // Zero gradients
    qlora.zero_grad();
}

// 5. Save adapters (32MB file)
save_adapter(&amp;qlora, "custom_adapter.json")?;
<span class="boring">}</span></code></pre></pre>
<p><strong>Result</strong>: Fine-tune 7B parameter model on consumer GPU with 8GB VRAM</p>
<h2 id="key-takeaways"><a class="header" href="#key-takeaways">Key Takeaways</a></h2>
<ol>
<li><strong>Tensors</strong> store data and gradients, enabling automatic differentiation</li>
<li><strong>Autograd</strong> computes gradients via reverse-mode differentiation on a tape-based graph</li>
<li><strong>Optimizers</strong> update parameters using various strategies (SGD, Adam, AdamW)</li>
<li><strong>LoRA</strong> trains low-rank adapters instead of full weights (99.9% parameter reduction)</li>
<li><strong>QLoRA</strong> quantizes base weights to 4-bit for 75% memory savings</li>
<li><strong>EXTREME TDD</strong> ensures zero defects through comprehensive testing</li>
</ol>
<h2 id="whats-next"><a class="header" href="#whats-next">What's Next?</a></h2>
<ul>
<li><strong><a href="../autograd/what-is-autograd.html">Autograd Engine</a></strong> - Deep dive into automatic differentiation</li>
<li><strong><a href="../optimizers/overview.html">Optimizers</a></strong> - Explore optimizer algorithms and theory</li>
<li><strong><a href="../lora/what-is-lora.html">LoRA/QLoRA</a></strong> - Master parameter-efficient fine-tuning</li>
<li><strong><a href="../examples/linear-regression.html">Examples</a></strong> - See practical applications</li>
</ul>
<hr />
<p><strong>Ready to explore the autograd engine?</strong> Continue to <a href="../autograd/what-is-autograd.html">What is Automatic Differentiation?</a> →</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="../getting-started/first-training-loop.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>

                            <a rel="next prefetch" href="../architecture/overview.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="../getting-started/first-training-loop.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

                    <a rel="next prefetch" href="../architecture/overview.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>

        <script src="../ace.js"></script>
        <script src="../editor.js"></script>
        <script src="../mode-rust.js"></script>
        <script src="../theme-dawn.js"></script>
        <script src="../theme-tomorrow_night.js"></script>

        <script src="../elasticlunr.min.js"></script>
        <script src="../mark.min.js"></script>
        <script src="../searcher.js"></script>

        <script src="../clipboard.min.js"></script>
        <script src="../highlight.js"></script>
        <script src="../book.js"></script>

        <!-- Custom JS scripts -->


    </div>
    </body>
</html>
